---
jupytext:
  formats: md:myst
  text_representation:
    extension: .md
    format_name: myst
kernelspec:
  display_name: Julia
  language: julia
  name: julia-1.6
---

# Числа с плавающей точкой

Множество действительных чисел $\real$ неограничено и непрерывно. Однако, в вычислительной практике используется множество *чисел с плавающей точкой* $\floatset\subset\real$, которое ограничено и дискретно. Это множество имеет арифметику, отличающуюся от арифметики в действительных чисел.

## Множество чисел с плавающей точкой

```{index} число; с плавающей точкой
```
```{index} see: экспонента; число с плавающей точкой
```
```{index} see: мантисса; число с плавающей точкой
```

:::{proof:definition} Число с плавающей точкой

Множество **чисел с плавающей точкой** $\floatset$ состоит из нуля и чисел вида

```{math}
:label: floatpoint
\pm (1 + f) \times 2^n,
```

где целое число $n\in\integer$ называют **экспонентой**, а $1+f$ **мантиссой**, при этом $f$ имеет вид

```{math}
:label: mantissa
f = \sum_{i=1}^d b_i \, 2^{-i}, \quad b_i\in\{0,1\},
```

где натуральное $d$ называют (в данном случае) двоичной **точностью**.

Можно сказать, что $f$ {eq}`mantissa` является дробной частью мантиссы.
:::

Используя нотацию из позиционных систем счисления, можно записать *в двоичной системе*

```{math}
1 + f = 1 + 0.\overline{b_1 b_2 ... b_d} = 1.\overline{b_1 b_2 ... b_d} \in [1,2).
```

Отсюда видно, что ближайшие мантисcы отстоят друг от друга на $2^{-d}$ (последний бит $b_d$).
Поэтому, между числами $2^n$ и $2^{n+1}$ находится $2^d$ равномерно распределённых чисел.
В свою очередь, отсюда следует, что числа с плавающей точной *распределены неравномерно* на числовой оси.

:::{proof:example}

Рассмотрим числа с точностью $d = 3$. Для $n=0$ получим $8$ чисел

$$
1, \: 1 + \frac{1}{8}, \: 1 + \frac{1}{4}, \: 1 + \frac{1}{4} + \frac{1}{8}, \:
1 + \frac{1}{2}, \: 1 + \frac{1}{2} + \frac{1}{8}, \: 1 + \frac{1}{2} + \frac{1}{4}, \:
1 + \frac{1}{2} + \frac{1}{4} + \frac{1}{8} = 1 + \frac{7}{8}.
$$

которые заключены в полуинтервале $[1,2)$ с промежутком $2^0 2^{-3} = 1/8$.

В свою очередь, для $n=1$ получим $8$ чисел в полуинтервале $[2, 4)$ с промежутком $2^1 2^{-3} = 1/4$

$$
(1+0)\times 2^1 = 2, \quad \bigg(1 + \frac{1}{8}\bigg) \times 2^1 = 2 + \frac{1}{4}
, \quad ..., \quad \bigg(1 + \frac{1}{2} + \frac{1}{4} + \frac{1}{8}\bigg) \times 2^1 = 3 + \frac{3}{4}.
$$

Аналогично, для $n=-1$ получим $8$ чисел в полуинтервале $[1/2,1)$ с промежуком $2^{-1}2^{-3}=1/16$.

:::

```{margin}
Для чисел с плавающей точкой верно равенство $1 + \macheps / 2 = 1$.
```
```{index} машинный ноль
```
```{index} see: машинный нуль; машинный ноль
```
Из примера видно, что наименьшее число с плавающей точкой, большее $1$ это $1 + 2^{-d}$. Разницу между этими числами $2^{-d}$ называют **машинным нулём** (машинным эпсилон, машинной точностью) $\macheps$.

Поскольку числа с плавающей точкой имеют конечную точность, сделаем оценку лучшего приближения.
Пусть $\float(x)\in\floatset$ ближайшее к действительному $x\in\real$ число с плавающей точкой. Расстояние для чисел в промежутке $[2^n, 2^{n+1})$ равняется $2^n \macheps = 2^{n-d}$. Поэтому число $x$ находится не далее, чем на $2^{n-d} / 2 = 2^{n-d-1}$ от $\float(x)$. Относительная ошибка приближения тогда

```{math}
\frac{|\float(x)-x|}{|x|} \le \frac{2^{n-d-1}}{2^n} \le \frac{1}{2}\macheps.
```

## Числа двойной точности
```{index} число; двойной точности

```
```{margin}
Последняя версия стандарта &ndash; IEEE 754-2019.

Поскольку в двоичном представлении первая цифра мантиссы нормализованного числа всегда 1, то её смысла хранить нет.
```
Число с плавающей точкой двойной точности `Float64` определил стандарт IEEE 754-1985.
Для `Float64` всего отводится 64 бита: один под знак числа, 11 под экспоненту и 52 под дробную часть мантиссы $f$.


```
  s eeeeeeeeeee mmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmmm
  ↑  экспонента                        мантисса
знак
1 бит  11 бит                           52 бита
```

Таким образом для `Float64` $d=52$ {eq}`mantissa`, а машинная точность $\macheps$ составляет

```{math}
:label: macheps_float64
\macheps = 2^{-52} \approx 2.2 \times 10^{-16}.
```

Экспонента $n$ {eq}`floatpoint` принимает значения $-1022 \le n \le 1023$. Максимальное значение в ` Float64` составляет почти $2^{1024} \approx 2 \times 10^{308}$. Числа крупнее принимают специальное значение-бесконечность `Inf`. Наименьшим положительным числом является $2^{-1022} \approx 2 \times 10^{-308}$, меньшие его становятся нулём. Отрицательные аналоги работают схожим образом.

Стоит отметить, что нулей в `Float64`, как и бесконечностей, два: `+0` и `-0`.

```{margin}
Да, на ноль делить можно.
```
Кроме того, существует ещё одно специальное значение **Not a Number**, `NaN`. Оно появляется в результате неопределённых операций: `±0/±0`, `±Inf/±Inf` и операций, в которых участвует `NaN`, что приводит к распространению `NaN` в вычислениях.

:::{proof:demo}
:::

```{raw} html
<div class="demo">
```
% todo: график распределение float64 на числовой прямой

**`Float64` в Julia**

Битовое представление `Float64`

```{code-cell}
@show typeof(2.784);
```

```{code-cell}
bitstring(2.784)
```

Функции `nextfloat` и `prevfloat` возвращают ближайшие следующее и предыдущее числа

```{code-cell}
[bitstring(prevfloat(1.0)), bitstring(1.0), bitstring(nextfloat(1.0))]
```

```{code-cell}
[prevfloat(1.0), 1.0, nextfloat(1.0)]
```

Определённые в {eq}`floatpoint` экспоненту и мантиссу также можно получить

```{code-cell}
x = 2.784
@show sign(x), exponent(x), significand(x);
```

Расстояние между числами в диапазоне $[2^n, 2^{n+1})$ можно получить с помощью функции `eps(x)`.
По умолчанию, `eps()` возвращает значение для единицы `1.0`, что является машинным нулём $\macheps$

```{code-cell}
@show eps();
@show log2(eps());
```

Пример вызова для для числа, отличного от `1.0`

```{code-cell}
@show eps(3.0);
@show prevfloat(3.0);
@show nextfloat(3.0);
```

Однако, стоит отметить, что `eps(x)` определяется как

```julia
eps(x) == max(x-prevfloat(x), nextfloat(x)-x)
```

например, для числа `2.0` проявится то, что оно находится на границе диапазонов $[1, 2), [2, 4)$

```{code-cell}
@show eps(2.0);
@show prevfloat(2.0);
@show nextfloat(2.0);
```

Наименьшее и наибольшее числа (но не `Inf` или `0`) получить можно так

```{code-cell}
@show floatmin(), floatmax();
```

Специальные значения можно получить с помощью констант `Inf` и `NaN`

```{code-cell}
[bitstring(Inf), bitstring(-Inf), bitstring(NaN)]
```

```{raw} html
</div>
```

## Особенности арифметики чисел с плавающей точкой

Конечная точность чисел с плавающей точкой приводит к **ошибкам округления**.
Рассмотрим на примерах ниже.

:::{proof:example}

**Oшибки округления**

Пусть требуется сложить $2.25 + 1.125$ c двоичной точностью $d=3$
Тогда сложение представится в виде

$$
\float(2.25) + \float(1.125) = \bigg(1+\frac{1}{8}\bigg)\times 2^1 + \bigg(1+\frac{1}{8}\bigg)\times 2^0.
$$

Чтобы его выполнить, необходимо сначала выравнять экспоненты слагаемых

$$
\require{cancel}
\bigg(1+\frac{1}{8}\bigg)\times 2^1 + \bigg(\frac{1}{2}+\cancel{\frac{1}{16}}\bigg)\times 2^1.
$$

На этом этапе происходит обрезание $1/16$, поскольку $1/16$ меньше точности $1/8$, с которой можно задать мантиссу.

Когда экспонентны выравнены, можно сложить мантиссы $(1 + 1/8) + (1/2)$. Получаем результат

$$
\bigg(1+ \frac{1}{2}+\frac{1}{8}\bigg)\times 2^1 = 3.25,
$$

который не равен сложению в действительныйх числах $2.25 + 1.125 = 3.375$.
:::

В случае `Float64` демонстрация ошибок округления может быть такой

```{code-cell}
@show 2.0 + nextfloat(1.0);
@show nextfloat(1.0);
```

Ошибки округления копятся, например, можно вычислить

$$
\frac{k}{10} - \sum_{i=1}^{k} 0.1
$$

```{code-cell}
ks = [10.0, 100.0, 1000.0, 10000.0]
@show Σ = [sum(0.1 for _ in 1:k) for k in ks]
@show exact = 0.1 .* ks;
```

При этом относительная ошибка копится

```{code-cell}
(exact .- Σ) ./ exact
```

% TODO
% Хороший график можно накодить
% https://stackoverflow.com/questions/249467/what-is-a-simple-example-of-floating-point-rounding-error

```{margin}
Так и поступают для вычисления рядов, например, $e^x = \sum_{n=0}^\infty x^n /n!$.
```

```{margin}
Также, см. [алгоритм Кэхэна](https://ru.wikipedia.org/wiki/%D0%90%D0%BB%D0%B3%D0%BE%D1%80%D0%B8%D1%82%D0%BC_%D0%9A%D1%8D%D1%85%D1%8D%D0%BD%D0%B0).
```
Ошибку округления можно уменьшить, если изменить порядок сложения

```{code-cell}
@show 0.1 + 0.1 + 0.1 + 0.1 + 0.1 + 0.1 + 0.1 + 0.1 + 0.1 + 0.1;
@show (0.1 + 0.1) + (0.1 + 0.1) + (0.1 + 0.1) + (0.1 + 0.1) + (0.1 + 0.1);
```

Более прикладным примером является работа с числами разных порядков

```{code-cell}
ϵ = 1e-6
@show (1.0 + ϵ)^2;
@show 1.0 + 2.0*ϵ + ϵ^2;
@show 1.0 + (2.0*ϵ + ϵ^2);
```

Машинный ноль {eq}`macheps_float64` на практике означает, что при сложении чисел двойной точности, отличающихся примерно в $10^{16}$ раз или более, одно из слагаемых потеряется

```{code-cell}
@show 1.0 + 1e-15;
@show 1.0 + 1e-16;
@show 1.0 + 1e15;
@show 1.0 + 1e16;
```

Ещё один пример неассоциативности. Он возникает на границе $2^n$ диапазонов $[2^{n-1}, 2^n)$ и $[2^n,2^{n+1})$

```{margin}
В англоязычной литературе см. *subtractive cancellation*.
```
```{code-cell}
@show (1.0 + eps()/2) - 1.0;
@show 1.0 + (eps()/2 - 1.0);
```

## Меры предосторожности и практика работы с float-числами

**Точность представления чисел**

```julia-repl
julia> 0.1 + 0.2  # Float64
0.30000000000000004

julia> 0.1f0 + 0.2f0  # Float32
0.3f0
```

Не все числа представимы в float точно, в реальности программист имеет дело с ближайшим к действительному float-числу. Сложение float-чисел может быть выполнено точно, например, результат 0.30000000000000004 верный, просто сложение происходило для приближений, а не исходных чисел. В разных представлениях могут быть разные результаты, так для `Float32` те же числа складываются иначе.

**Сравнение чисел**

Когда необходимо сравнивать числа, используйте неточное сравнение `isapprox`, при этом лучше использовать относительную погрешность, а не абсолютную.

Будьте аккуратнее в точных сравнениях. Например, вам необходимо найти отрицательную энергию, тогда сравнение вида `E < 0` иногда не подходит, поскольку `E` может быть порядка $-\macheps$: считать ли такое значение значение физически отрицательным -- решать вам.

**Числа сильно разных точностей**

Работая с `Float64`, старайтесь не допускать сложений чисел, отличающихся примерно в $10^{16}$ раз или более.

**Сложение неассоциативно**

Малое складывать с малым, а крупное с крупным.

Осторожнее с

- С суммами большого числа слагаемых (ряды, циклы);
- Возведением в степень.

**Subtractive cancellation**

Осторожнее с вычитанием чисел близких по значению. Примеры из [Википедии](https://en.wikipedia.org/wiki/Catastrophic_cancellation#In_numerical_algorithms). Операции происходят с конечной точностью, поэтому иногда ошибка вычитания приближений может сильно превышать вычитание точных чисел. Алгебраические преобразования с вычисляемым выражением могут помочь снизить ошибку.
